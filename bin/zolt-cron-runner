#!/bin/bash
# zolt-cron-runner - Wrapper script for scheduled reconnaissance automation
# This script is called by cron to execute the daily reconnaissance workflow

set -e  # Exit on error

# -----------------------------------------------------------------------------
# CONFIGURATION & DEFAULTS
# -----------------------------------------------------------------------------
SCRIPT_NAME="zolt-cron-runner"
VERSION="1.0.0"

# Default values
DRY_RUN=false
PHASE="all"
CONFIG_FILE=""
VERBOSE=false
CONTINUE_ON_FAILURE=false

# Colors for output (only if terminal)
if [ -t 1 ]; then
    RED='\033[0;31m'
    GREEN='\033[0;32m'
    YELLOW='\033[1;33m'
    BLUE='\033[0;34m'
    MAGENTA='\033[0;35m'
    CYAN='\033[0;36m'
    BOLD='\033[1m'
    NC='\033[0m' # No Color
else
    RED=''
    GREEN=''
    YELLOW=''
    BLUE=''
    MAGENTA=''
    CYAN=''
    BOLD=''
    NC=''
fi

# -----------------------------------------------------------------------------
# FUNCTIONS
# -----------------------------------------------------------------------------

# Print colored output
print_info() {
    echo -e "${BLUE}[INFO]${NC} $*"
}

print_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $*"
}

print_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $*"
}

print_error() {
    echo -e "${RED}[ERROR]${NC} $*" >&2
}

print_phase() {
    echo -e "\n${MAGENTA}━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━${NC}"
    echo -e "${MAGENTA}PHASE:${NC} $*"
    echo -e "${MAGENTA}━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━${NC}\n"
}

# Print usage information
usage() {
    cat << EOF
zolt-cron-runner v${VERSION}

Wrapper script for scheduled daily reconnaissance automation.

USAGE:
    $SCRIPT_NAME --config <file> [OPTIONS]

OPTIONS:
    --config FILE       Configuration file (TOML)
    --phase PHASE       Run specific phase only (default: all)
                        Options: subdomain-enum, probe-alive, crawl-sites,
                                javascript, parameters, diff
    --dry-run           Show what would be done without executing
    --continue-on-fail  Continue to next phase if a tool fails
    --verbose           Enable verbose output
    -h, --help          Show this help message

EXAMPLES:
    # Run all phases
    $SCRIPT_NAME --config daily-recon.toml

    # Run specific phase
    $SCRIPT_NAME --config daily-recon.toml --phase subdomain-enum

    # Dry run
    $SCRIPT_NAME --config daily-recon.toml --dry-run

EOF
}

# Parse command line arguments
parse_args() {
    while [[ $# -gt 0 ]]; do
        case $1 in
            --config)
                CONFIG_FILE="$2"
                shift 2
                ;;
            --phase)
                PHASE="$2"
                shift 2
                ;;
            --dry-run)
                DRY_RUN=true
                shift
                ;;
            --continue-on-fail|--continue-on-failure)
                CONTINUE_ON_FAILURE=true
                shift
                ;;
            --verbose|-v)
                VERBOSE=true
                shift
                ;;
            -h|--help)
                usage
                exit 0
                ;;
            *)
                print_error "Unknown option: $1"
                usage
                exit 1
                ;;
        esac
    done

    # Validate required arguments
    if [[ -z "$CONFIG_FILE" ]]; then
        print_error "--config is required"
        usage
        exit 1
    fi

    if [[ ! -f "$CONFIG_FILE" ]]; then
        print_error "Config file not found: $CONFIG_FILE"
        exit 1
    fi
}

# Extract value from TOML
get_toml_value() {
    local file="$1"
    local key="$2"
    local default="$3"

    # Try to extract the value
    local value=$(grep -E "^${key}\s*=\s*\"" "$file" | sed -E "s/^${key}\s*=\s*\"(.*)\"\s*$/\1/" | head -1)

    if [[ -z "$value" ]]; then
        echo "$default"
    else
        echo "$value"
    fi
}

# Get output directory from config
get_output_dir() {
    local dir=$(get_toml_value "$CONFIG_FILE" "output_dir" "./recon")
    # Replace {scope.output_dir} with actual value
    dir="${dir/\{scope.output_dir\}/./recon}"
    echo "$dir"
}

# Setup directory structure
setup_directories() {
    local output_dir="$(get_output_dir)"

    if [[ "$DRY_RUN" == true ]]; then
        print_info "[DRY RUN] Would create directories:"
    fi

    dirs=(
        "$output_dir/subdomains/history"
        "$output_dir/urls/history"
        "$output_dir/js/history"
        "$output_dir/params/history"
        "logs/daily"
        ".zolt"
    )

    for dir in "${dirs[@]}"; do
        if [[ "$DRY_RUN" == true ]]; then
            echo "  $dir"
        else
            mkdir -p "$dir"
        fi
    done

    if [[ "$DRY_RUN" != true ]]; then
        print_success "Directories created"
    fi
}

# Check if another instance is running
check_lock() {
    local lock_file=".zolt/schedule.lock"

    if [[ -f "$lock_file" ]]; then
        local pid=$(cat "$lock_file")
        if kill -0 "$pid" 2>/dev/null; then
            print_error "Another instance is running (PID: $pid)"
            exit 1
        else
            print_warning "Stale lock file found (PID: $pid), removing"
            rm -f "$lock_file"
        fi
    fi

    if [[ "$DRY_RUN" != true ]]; then
        echo $$ > "$lock_file"
        print_success "Lock acquired (PID: $$)"
    fi
}

# Remove lock file
remove_lock() {
    if [[ "$DRY_RUN" != true && -f ".zolt/schedule.lock" ]]; then
        rm -f ".zolt/schedule.lock"
        print_success "Lock released"
    fi
}

# Setup logging
setup_logging() {
    local log_dir="logs/daily"
    local date="$(date +%Y-%m-%d)"
    LOG_FILE="${log_dir}/schedule-${date}.log"

    if [[ "$DRY_RUN" == true ]]; then
        print_info "[DRY RUN] Would log to: $LOG_FILE"
    else
        print_success "Logging to: $LOG_FILE"
        print_info "[$(date)] Starting daily recon: $CONFIG_FILE" >> "$LOG_FILE"
    fi
}

# Log a message
log_message() {
    local level="$1"
    local message="$2"

    if [[ "$DRY_RUN" != true ]]; then
        echo "[$(date '+%Y-%m-%d %H:%M:%S')] [$level] $message" >> "$LOG_FILE"
    fi

    if [[ "$VERBOSE" == true || "$level" == "ERROR" ]]; then
        case $level in
            INFO) print_info "$message" ;;
            SUCCESS) print_success "$message" ;;
            WARNING) print_warning "$message" ;;
            ERROR) print_error "$message" ;;
        esac
    fi
}

# Extract phase configuration from TOML
get_phase_config() {
    local phase_id="$1"
    local output_dir="$(get_output_dir)"

    # Extract tools for this phase
    # This is a simplified version - real implementation would use proper TOML parsing
    print_info "Extracting config for phase: $phase_id"
}

# Run a tool with timeout
run_tool() {
    local name="$1"
    local command="$2"
    local timeout="$3"

    log_message "INFO" "Running tool: $name (timeout: ${timeout}s)"

    if [[ "$DRY_RUN" == true ]]; then
        print_info "[DRY RUN] Would run: $name"
        print_info "  Command: $command"
        print_info "  Timeout: ${timeout}s"
        return 0
    fi

    # Create temp file for timeout
    local temp_cmd=$(mktemp)
    echo "$command" > "$temp_cmd"
    chmod +x "$temp_cmd"

    # Run with timeout
    if timeout -s SIGTERM "${timeout}s" bash "$temp_cmd" >> "$LOG_FILE" 2>&1; then
        log_message "SUCCESS" "Tool completed: $name"
        rm -f "$temp_cmd"
        return 0
    else
        local exit_code=$?
        log_message "ERROR" "Tool failed: $name (exit code: $exit_code)"
        rm -f "$temp_cmd"

        if [[ "$CONTINUE_ON_FAILURE" == true ]]; then
            print_warning "Continuing despite failure"
            return 0
        else
            return 1
        fi
    fi
}

# Merge tool outputs
merge_outputs() {
    local input_pattern="$1"
    local output_file="$2"
    local deduplicate="$3"

    log_message "INFO" "Merging outputs: $input_pattern -> $output_file"

    if [[ "$DRY_RUN" == true ]]; then
        print_info "[DRY RUN] Would merge files matching: $input_pattern"
        return 0
    fi

    # Find all input files
    if compgen -G "$input_pattern" > /dev/null; then
        if [[ "$deduplicate" == true ]]; then
            cat $input_pattern | sort -u > "$output_file"
        else
            cat $input_pattern > "$output_file"
        fi
        log_message "SUCCESS" "Merged outputs: $(wc -l < "$output_file") lines"
    else
        log_message "WARNING" "No files found matching: $input_pattern"
        touch "$output_file"
    fi
}

# Run phase
run_phase() {
    local phase_id="$1"
    local date="$(date +%Y-%m-%d)"

    print_phase "$phase_id"

    # Get output directory
    local output_dir="$(get_output_dir)"

    # Run based on phase_id
    case $phase_id in
        subdomain-enum)
            log_message "INFO" "Starting subdomain enumeration phase"

            run_tool "subfinder" \
                "subfinder -dL $(get_toml_value "$CONFIG_FILE" 'target_file' 'targets.txt') -o $output_dir/subdomains/subfinder-$date.txt -silent" \
                "900"  # 15 minutes

            run_tool "amass" \
                "amass enum -df $(get_toml_value "$CONFIG_FILE" 'target_file' 'targets.txt') -o $output_dir/subdomains/amass-$date.txt -silent" \
                "900"

            run_tool "assetfinder" \
                "assetfinder -df $(get_toml_value "$CONFIG_FILE" 'target_file' 'targets.txt') | tee $output_dir/subdomains/assetfinder-$date.txt" \
                "600"

            merge_outputs "$output_dir/subdomains/*-$date.txt" \
                         "$output_dir/subdomains/all-$date.txt" \
                         "true"
            ;;

        probe-alive)
            log_message "INFO" "Starting HTTP probing phase"

            run_tool "httpx" \
                "httpx -l $output_dir/subdomains/all-$date.txt -o $output_dir/subdomains/alive-$date.json -json -sc -title -td -pa -silent" \
                "1200"  # 20 minutes

            # Extract URLs from JSON
            if [[ "$DRY_RUN" != true ]]; then
                cat "$output_dir/subdomains/alive-$date.json" | jq -r '.url' | sort -u > "$output_dir/subdomains/alive-$date.txt"
            fi
            ;;

        crawl-sites)
            log_message "INFO" "Starting web crawling phase"

            run_tool "katana" \
                "katana -list $output_dir/subdomains/alive-$date.txt -o $output_dir/urls/katana-$date.txt -jc -jsl -d 3 -silent" \
                "1800"

            run_tool "gospider" \
                "gospider -S $output_dir/subdomains/alive-$date.txt -o $output_dir/urls/gospider-$date.txt -q --js --subs --robots --sitemap" \
                "1500"

            cat $output_dir/subdomains/alive-$date.txt | waybackurls > "$output_dir/urls/wayback-$date.txt"

            merge_outputs "$output_dir/urls/*-$date.txt" \
                         "$output_dir/urls/all-$date.txt" \
                         "true"
            ;;

        javascript)
            log_message "INFO" "Starting JavaScript discovery phase"

            grep -E '\.js$|\.js\\?' "$output_dir/urls/all-$date.txt" | sort -u > "$output_dir/js/files-$date.txt"
            ;;

        parameters)
            log_message "INFO" "Starting parameter extraction phase"

            run_tool "unfurl" \
                "unfurl -u keys -i $output_dir/urls/all-$date.txt -o $output_dir/urls/params-$date.txt" \
                "300"
            ;;

        *)
            print_error "Unknown phase: $phase_id"
            return 1
            ;;
    esac
}

# Run diff comparison
run_diff() {
    local date="$(date +%Y-%m-%d)"
    local output_dir="$(get_output_dir)"

    print_phase "Diff Comparison"

    # Copy today's files to history
    for file in subdomains/all urls/all js/files urls/params; do
        if [[ -f "$output_dir/$file-$date.txt" ]]; then
            # Create directory if it doesn't exist
            mkdir -p "$output_dir/$(dirname $file)/history"
            cp "$output_dir/$file-$date.txt" "$output_dir/$file/history/$date.txt"
        fi
    done

    # Find yesterday's file and generate diff
    local yesterday="$(date -d '1 day ago' +%Y-%m-%d)"

    if [[ -f "$output_dir/subdomains/history/$yesterday.txt" ]]; then
        log_message "INFO" "Comparing subdomains: yesterday vs today"

        comm -13 <(sort "$output_dir/subdomains/history/$yesterday.txt") \
                 <(sort "$output_dir/subdomains/all-$date.txt") \
                 > "$output_dir/subdomains/diff-new-$date.txt"

        local new_count=$(wc -l < "$output_dir/subdomains/diff-new-$date.txt")
        log_message "SUCCESS" "New subdomains: $new_count"

        if [[ "$new_count" -gt 0 ]]; then
            print_success "New subdomains found:"
            head -10 "$output_dir/subdomains/diff-new-$date.txt" | while read -r subdomain; do
                echo "  $subdomain"
            done
        fi
    else
        log_message "INFO" "No previous data found, creating baseline"
        print_info "First run - baseline created. Future runs will show diffs."
    fi
}

# Parse args
parse_args "$@"

# Check operations
if [[ "$DRY_RUN" == true ]]; then
    print_info "========== DRY RUN MODE =========="
fi

# Setup
check_lock
trap remove_lock EXIT
setup_directories
setup_logging

# Main execution
log_message "INFO" "Starting zolt-cron-runner v$VERSION"
log_message "INFO" "Config: $CONFIG_FILE"
log_message "INFO" "Phase: $PHASE"

# Run based on phase argument
case $PHASE in
    all)
        log_message "INFO" "Executing all phases"
        run_phase "subdomain-enum"
        run_phase "probe-alive"
        run_phase "crawl-sites"
        run_phase "javascript"
        run_phase "parameters"
        run_diff
        ;;
    *)
        log_message "INFO" "Executing single phase: $PHASE"
        run_phase "$PHASE"
        ;;
esac

# Cleanup
remove_lock
log_message "SUCCESS" "Daily recon completed successfully"

print_success "Daily reconnaissance completed!"
print_info "Log file: $LOG_FILE"

exit 0
